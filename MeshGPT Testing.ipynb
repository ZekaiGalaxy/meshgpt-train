{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:12.944690Z","iopub.status.busy":"2023-12-19T01:39:12.944345Z","iopub.status.idle":"2023-12-19T01:39:38.152713Z","shell.execute_reply":"2023-12-19T01:39:38.151433Z","shell.execute_reply.started":"2023-12-19T01:39:12.944662Z"},"trusted":true},"outputs":[],"source":["!pip install -q git+https://github.com/MarcusLoppe/meshgpt-pytorch.git trimesh"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:38.155749Z","iopub.status.busy":"2023-12-19T01:39:38.155103Z","iopub.status.idle":"2023-12-19T01:39:44.048426Z","shell.execute_reply":"2023-12-19T01:39:44.047605Z","shell.execute_reply.started":"2023-12-19T01:39:38.155692Z"},"trusted":true},"outputs":[],"source":["import torch\n","import trimesh\n","import numpy as np\n","import os\n","import csv \n","import json\n","import math \n","\n","from meshgpt_pytorch import (\n","    MeshTransformerTrainer,\n","    MeshAutoencoderTrainer,\n","    MeshAutoencoder,\n","    MeshTransformer\n",")\n","\n","\n","\n","\n"," \n","\n","\n","  \n","\n","\n","  \n","                        \n","         "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:44.050017Z","iopub.status.busy":"2023-12-19T01:39:44.049685Z","iopub.status.idle":"2023-12-19T01:39:44.063671Z","shell.execute_reply":"2023-12-19T01:39:44.062641Z","shell.execute_reply.started":"2023-12-19T01:39:44.049992Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader \n","from tqdm import tqdm\n","import numpy as np\n","import torch\n"," \n","\n","         "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:39:44.066146Z","iopub.status.busy":"2023-12-19T01:39:44.065812Z","iopub.status.idle":"2023-12-19T01:39:52.313349Z","shell.execute_reply":"2023-12-19T01:39:52.312381Z","shell.execute_reply.started":"2023-12-19T01:39:44.066116Z"},"trusted":true},"outputs":[],"source":["\n","\n","unique_values = set(item[\"texts\"] for item in dataset.data)\n","\n","print(len(unique_values))  \n","print(unique_values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["autoencoder = MeshAutoencoder( \n","    num_discrete_coors = 128  , \n",") \n","total_params = sum(p.numel() for p in autoencoder.encoders.parameters())\n","print(f\"encoders Total parameters: {total_params}\")\n","total_params = sum(p.numel() for p in autoencoder.decoders.parameters())\n","print(f\"decoders Total parameters: {total_params}\")  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-19T01:44:00.715656Z","iopub.status.busy":"2023-12-19T01:44:00.714727Z","iopub.status.idle":"2023-12-19T12:00:40.840982Z","shell.execute_reply":"2023-12-19T12:00:40.840110Z","shell.execute_reply.started":"2023-12-19T01:44:00.715620Z"},"trusted":true},"outputs":[],"source":["total_params = sum(p.numel() for p in autoencoder.encoders.parameters())\n","print(f\"Total parameters: {total_params}\")\n","print(autoencoder.encoders)\n","\n","autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder,learning_rate = 1e-3, \n","                                             warmup_steps = 10,\n","                                             dataset = dataset,   \n","                                             num_train_steps=100,\n","                                             batch_size=16,\n","                                             grad_accum_every=1)\n","\n","loss = autoencoder_trainer.train(40,stop_at_loss = 0.25)   \n","autoencoder_trainer = MeshAutoencoderTrainer(model =autoencoder,learning_rate = 1e-4, \n","                                             warmup_steps = 10,\n","                                             dataset = dataset,\n","                                             checkpoint_every_epoch = 20,  \n","                                             num_train_steps=100,\n","                                             batch_size=16,\n","                                             grad_accum_every=1)\n","\n","loss = autoencoder_trainer.train(180,stop_at_loss = 0.25)   \n","autoencoder_trainer.save(f'./mesh-encoder_2_loss_{loss:.3f}.pt') "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d) \n","max_seq =  max_length * 6  \n","print(max_length)\n","print(max_seq)\n","transformer = MeshTransformer(\n","    autoencoder,\n","    dim = 768,\n","    max_seq_len = max_seq,\n","    condition_on_text = True\n",")\n","total_params = sum(p.numel() for p in transformer.parameters())\n","print(f\"Total parameters: {total_params}\") "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Untested, but should work (?)\n","\n","#dataset.embed_texts(transformer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" \n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100,   dataset = dataset,\n","                                 learning_rate = 1e-1, batch_size=2)\n","trainer.train(80,stop_at_loss = 0.00009)   \n","\n"," \n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100,  dataset = dataset,\n","                                 learning_rate = 1e-2, batch_size=2)\n","trainer.train(80,stop_at_loss = 0.00009)    \n","\n","trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100,  dataset = dataset,\n","                                 learning_rate = 1e-4, batch_size=2)\n","trainer.train(80,stop_at_loss = 0.00009)   \n","\n","trainer.save(f'./mesh-transformer_2_{loss:.3f}.pt')    "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["unique_values = set(item[\"texts\"] for item in dataset.data)\n","print(len(unique_values))  \n","coords = []\n","for text in unique_values: \n","    print(f\"doing {text}\")\n","    faces_coordinates = transformer.generate(texts = [text]) \n","    coords.append(faces_coordinates)\n","    tensor_data = faces_coordinates[0].cpu()\n","    \n","    numpy_data = tensor_data.numpy().reshape(-1, 3)\n","    \n","    obj_file_content = \"\"\n","    \n","    for vertex in numpy_data:\n","        obj_file_content += f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\"\n","\n","    for i in range(1, len(numpy_data), 3):\n","        obj_file_content += f\"f {i} {i + 1} {i + 2}\\n\"\n","\n","    # Save to a file\n","    obj_file_path = f'./tests/3d_output_{text}.obj'\n","    with open(obj_file_path, \"w\") as file:\n","        file.write(obj_file_content)\n","\n","    print(obj_file_path) \n","    \n","    \n","all_vertices = []\n","all_faces = []\n","vertex_offset = 0\n"," \n","translation_distance = 0.3  \n","\n","for r, faces_coordinates in enumerate(coords): \n","    tensor_data = faces_coordinates[0].cpu()\n","\n","    numpy_data = tensor_data.numpy().reshape(-1, 3)\n","\n","    # Translate the model to avoid overlapping\n","    numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)  # Adjust X coordinate\n","\n","    # Accumulate vertices\n","    for vertex in numpy_data:\n","        all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n","\n","    # Accumulate faces with adjusted indices\n","    for i in range(1, len(numpy_data), 3):\n","        all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n","\n","    # Update the vertex offset for the next model\n","    vertex_offset += len(numpy_data)\n","\n","# Combine vertices and faces\n","obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n","\n","# Save to a single file\n","obj_file_path = f\"./tests/3d_models_all.obj\"\n","with open(obj_file_path, \"w\") as file:\n","    file.write(obj_file_content)\n","\n","print(obj_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","coords_all = []\n","for text in set(item[\"texts\"] for item in dataset.data): \n","    print(f\"Doing {text}\")\n","    coords = []\n","    for r in np.arange(0, 1.0, 0.1):\n","        faces_coordinates = transformer.generate(temperature=r, texts = [text]) \n","        coords.append(faces_coordinates)\n","    coords_all.append(coords)\n","    \n","    all_vertices = []\n","    all_faces = []\n","    vertex_offset = 0\n","\n","    # Translation distance for each model\n","    translation_distance = 0.3  # Adjust as needed\n","\n","    for r, faces_coordinates in enumerate(coords): \n","        tensor_data = faces_coordinates[0].cpu()\n","\n","        numpy_data = tensor_data.numpy().reshape(-1, 3)\n","\n","        # Translate the model to avoid overlapping\n","        numpy_data[:, 0] += translation_distance * (r / 0.2 - 1)  # Adjust X coordinate\n","\n","        # Accumulate vertices\n","        for vertex in numpy_data:\n","            all_vertices.append(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n","\n","        # Accumulate faces with adjusted indices\n","        for i in range(1, len(numpy_data), 3):\n","            all_faces.append(f\"f {i + vertex_offset} {i + 1 + vertex_offset} {i + 2 + vertex_offset}\\n\")\n","\n","        # Update the vertex offset for the next model\n","        vertex_offset += len(numpy_data)\n","\n","    # Combine vertices and faces\n","    obj_file_content = \"\".join(all_vertices) + \"\".join(all_faces)\n","\n","    # Save to a single file\n","    obj_file_path = f\"./results/3d_models_{text}_temps.obj\"\n","    with open(obj_file_path, \"w\") as file:\n","        file.write(obj_file_content)\n","\n","    print(obj_file_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def loadModels():\n","    autoencoder = MeshAutoencoder(\n","        dim = 576,\n","        encoder_depth = 6,\n","        decoder_depth = 6,\n","        num_discrete_coors = 128  ,\n","        local_attn_depth =0, \n","        \n","    )\n","    autoencoder_trainer = MeshAutoencoderTrainer(model = autoencoder,\n","                                    learning_rate = 1e-1, \n","                                                checkpoint_every_epoch= 5,\n","                                                warmup_steps = 10,\n","                                                dataset = dataset,  \n","                                                num_train_steps=100,\n","                                                batch_size=2,\n","                                                grad_accum_every=1)\n","\n","    autoencoder_trainer.load(r\"mesh-encoder_last.pt\")\n","    encoder = autoencoder_trainer.model\n","    max_length =  max(len(d[\"faces\"]) for d in dataset if \"faces\" in d) \n","    max_seq =  max_length * 6  \n","    \n","    transformer = MeshTransformer(\n","        autoencoder,\n","        dim = 768,\n","        max_seq_len = max_seq,\n","        condition_on_text = True)\n","     \n","    trainer = MeshTransformerTrainer(model = transformer,warmup_steps = 10,grad_accum_every=1,num_train_steps=100, checkpoint_folder = r\"F:\\MachineLearning\\Mesh\\MeshGPT\\checkpoints\" , dataset = dataset,\n","                                    learning_rate = 1e-3, batch_size=2) \n","    trainer.load(r\"mesh-transformer.pt\")\n","    transformer = trainer.model\n","    return transformer, encoder\n","\n","#transformer, autoencoder =  loadModels() "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4189032,"sourceId":7234116,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
